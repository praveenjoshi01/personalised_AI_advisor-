{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:35:56.395130Z",
     "start_time": "2019-04-28T23:35:53.003684Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as mn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import abc\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import abc\n",
    "import re\n",
    "import nltk\n",
    "from sklearn import model_selection \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:35:56.527854Z",
     "start_time": "2019-04-28T23:35:56.397132Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:35:56.533840Z",
     "start_time": "2019-04-28T23:35:56.529852Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:35:57.003723Z",
     "start_time": "2019-04-28T23:35:56.535834Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "import datetime\n",
    "import missingno as mn\n",
    "import pylab as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:35:57.014704Z",
     "start_time": "2019-04-28T23:35:57.004691Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:35:57.020655Z",
     "start_time": "2019-04-28T23:35:57.016689Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:35:57.142825Z",
     "start_time": "2019-04-28T23:35:57.021648Z"
    }
   },
   "outputs": [],
   "source": [
    "featureDF_nw = pd.read_csv('nw_feature_woText_MSFT.csv')\n",
    "featureDF_tw = pd.read_csv('tw_feature_woText_MSFT.csv')\n",
    "targetDF_ = pd.read_csv('FIwithTargetwithFTT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:35:57.149468Z",
     "start_time": "2019-04-28T23:35:57.144487Z"
    }
   },
   "outputs": [],
   "source": [
    "def getStartEndDateShape(dfz):\n",
    "    startDate = str(min(dfz['date']))\n",
    "    endDate = str(max(dfz['date']))\n",
    "    print('startDate', startDate)\n",
    "    print('endDate', endDate)\n",
    "    print('shape', dfz.shape)\n",
    "    print('---------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:00.215961Z",
     "start_time": "2019-04-28T23:36:00.205023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startDate 2004/07/21\n",
      "endDate 2019/03/28\n",
      "shape (4020, 24)\n",
      "---------------------------\n",
      "startDate 2015/05/04\n",
      "endDate 2019/04/04\n",
      "shape (1426, 25)\n",
      "---------------------------\n",
      "startDate 2003/04/30\n",
      "endDate 2019/04/03\n",
      "shape (4010, 32)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "getStartEndDateShape(featureDF_nw)\n",
    "getStartEndDateShape(featureDF_tw)\n",
    "getStartEndDateShape(targetDF_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:00.791083Z",
     "start_time": "2019-04-28T23:36:00.781134Z"
    }
   },
   "outputs": [],
   "source": [
    "targtWithDateForJoin =pd.DataFrame()\n",
    "targtWithDateForJoin['date'] = targetDF_.date.tolist()\n",
    "targtWithDateForJoin['target'] = targetDF_.Target.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T05:59:14.290447Z",
     "start_time": "2019-04-11T05:59:14.286449Z"
    }
   },
   "source": [
    "# Formulation of overall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:08.953020Z",
     "start_time": "2019-04-28T23:36:08.938106Z"
    }
   },
   "outputs": [],
   "source": [
    "featureDF_nw.date = pd.to_datetime(featureDF_nw.date)\n",
    "targtWithDateForJoin.date = pd.to_datetime(targtWithDateForJoin.date)\n",
    "featureDF_tw.date = pd.to_datetime(featureDF_tw.date)\n",
    "targetDF_.date = pd.to_datetime(targetDF_.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:22.580578Z",
     "start_time": "2019-04-28T23:36:22.558643Z"
    }
   },
   "outputs": [],
   "source": [
    "result =pd.merge( targetDF_,featureDF_nw, how='outer', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:22.899501Z",
     "start_time": "2019-04-28T23:36:22.876590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startDate 2003-04-30 00:00:00\n",
      "endDate 2019-04-03 00:00:00\n",
      "shape (4749, 55)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "getStartEndDateShape(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:23.265639Z",
     "start_time": "2019-04-28T23:36:23.250651Z"
    }
   },
   "outputs": [],
   "source": [
    "result =pd.merge( result,featureDF_tw, how='outer', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:23.564368Z",
     "start_time": "2019-04-28T23:36:23.539434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startDate 2003-04-30 00:00:00\n",
      "endDate 2019-04-04 00:00:00\n",
      "shape (5004, 79)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "getStartEndDateShape(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:23.836450Z",
     "start_time": "2019-04-28T23:36:23.822444Z"
    }
   },
   "outputs": [],
   "source": [
    "result.sort_values(by='date',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:24.113088Z",
     "start_time": "2019-04-28T23:36:24.098112Z"
    }
   },
   "outputs": [],
   "source": [
    "result = result.ffill()\n",
    "result.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:24.943139Z",
     "start_time": "2019-04-28T23:36:24.912224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>sma2</th>\n",
       "      <th>sma2_1</th>\n",
       "      <th>sma2_increment</th>\n",
       "      <th>sma2_1_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>disgust_y</th>\n",
       "      <th>anticipation_y</th>\n",
       "      <th>fear_y</th>\n",
       "      <th>trust_y</th>\n",
       "      <th>tb_polarity_y</th>\n",
       "      <th>tb_subjectivity_y</th>\n",
       "      <th>hiv4_positive_y</th>\n",
       "      <th>hiv4_negative_y</th>\n",
       "      <th>hiv4_polarity_y</th>\n",
       "      <th>hiv4_subjectivity_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.730000</td>\n",
       "      <td>25.879999</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>25.570000</td>\n",
       "      <td>18.536860</td>\n",
       "      <td>55566800.0</td>\n",
       "      <td>25.840001</td>\n",
       "      <td>25.670000</td>\n",
       "      <td>0.170001</td>\n",
       "      <td>0.310001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.540001</td>\n",
       "      <td>25.950001</td>\n",
       "      <td>25.340000</td>\n",
       "      <td>25.719999</td>\n",
       "      <td>18.645597</td>\n",
       "      <td>42085800.0</td>\n",
       "      <td>25.635001</td>\n",
       "      <td>25.840001</td>\n",
       "      <td>-0.205000</td>\n",
       "      <td>0.170001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.650000</td>\n",
       "      <td>26.290001</td>\n",
       "      <td>25.559999</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>18.921083</td>\n",
       "      <td>52695400.0</td>\n",
       "      <td>25.595001</td>\n",
       "      <td>25.635001</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>-0.205000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.250000</td>\n",
       "      <td>26.389999</td>\n",
       "      <td>25.840000</td>\n",
       "      <td>25.860001</td>\n",
       "      <td>18.747093</td>\n",
       "      <td>50391500.0</td>\n",
       "      <td>25.950000</td>\n",
       "      <td>25.595001</td>\n",
       "      <td>0.354999</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.860001</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>25.820000</td>\n",
       "      <td>26.370001</td>\n",
       "      <td>19.116816</td>\n",
       "      <td>54299500.0</td>\n",
       "      <td>26.055001</td>\n",
       "      <td>25.950000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.354999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open       High        Low      Close  Adj Close      Volume  \\\n",
       "0  25.730000  25.879999  25.250000  25.570000  18.536860  55566800.0   \n",
       "1  25.540001  25.950001  25.340000  25.719999  18.645597  42085800.0   \n",
       "2  25.650000  26.290001  25.559999  26.100000  18.921083  52695400.0   \n",
       "3  26.250000  26.389999  25.840000  25.860001  18.747093  50391500.0   \n",
       "4  25.860001  26.500000  25.820000  26.370001  19.116816  54299500.0   \n",
       "\n",
       "        sma2     sma2_1  sma2_increment  sma2_1_increment  ...  disgust_y  \\\n",
       "0  25.840001  25.670000        0.170001          0.310001  ...        0.0   \n",
       "1  25.635001  25.840001       -0.205000          0.170001  ...        0.0   \n",
       "2  25.595001  25.635001       -0.040000         -0.205000  ...        0.0   \n",
       "3  25.950000  25.595001        0.354999         -0.040000  ...        0.0   \n",
       "4  26.055001  25.950000        0.105000          0.354999  ...        0.0   \n",
       "\n",
       "   anticipation_y  fear_y  trust_y  tb_polarity_y  tb_subjectivity_y  \\\n",
       "0             0.0     0.0      0.0            0.0                0.0   \n",
       "1             0.0     0.0      0.0            0.0                0.0   \n",
       "2             0.0     0.0      0.0            0.0                0.0   \n",
       "3             0.0     0.0      0.0            0.0                0.0   \n",
       "4             0.0     0.0      0.0            0.0                0.0   \n",
       "\n",
       "   hiv4_positive_y  hiv4_negative_y  hiv4_polarity_y  hiv4_subjectivity_y  \n",
       "0              0.0              0.0              0.0                  0.0  \n",
       "1              0.0              0.0              0.0                  0.0  \n",
       "2              0.0              0.0              0.0                  0.0  \n",
       "3              0.0              0.0              0.0                  0.0  \n",
       "4              0.0              0.0              0.0                  0.0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:25.413312Z",
     "start_time": "2019-04-28T23:36:25.390386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>sma2</th>\n",
       "      <th>sma2_1</th>\n",
       "      <th>sma2_increment</th>\n",
       "      <th>sma2_1_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>disgust_y</th>\n",
       "      <th>anticipation_y</th>\n",
       "      <th>fear_y</th>\n",
       "      <th>trust_y</th>\n",
       "      <th>tb_polarity_y</th>\n",
       "      <th>tb_subjectivity_y</th>\n",
       "      <th>hiv4_positive_y</th>\n",
       "      <th>hiv4_negative_y</th>\n",
       "      <th>hiv4_polarity_y</th>\n",
       "      <th>hiv4_subjectivity_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>118.070000</td>\n",
       "      <td>118.320000</td>\n",
       "      <td>116.959999</td>\n",
       "      <td>117.940002</td>\n",
       "      <td>117.940002</td>\n",
       "      <td>25399800.0</td>\n",
       "      <td>117.755001</td>\n",
       "      <td>117.659999</td>\n",
       "      <td>0.095001</td>\n",
       "      <td>-0.590001</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>47.475081</td>\n",
       "      <td>141.259152</td>\n",
       "      <td>648.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>122.033564</td>\n",
       "      <td>73.387608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>118.949997</td>\n",
       "      <td>119.110001</td>\n",
       "      <td>118.099998</td>\n",
       "      <td>119.019997</td>\n",
       "      <td>119.019997</td>\n",
       "      <td>22789100.0</td>\n",
       "      <td>118.509998</td>\n",
       "      <td>117.755001</td>\n",
       "      <td>0.754998</td>\n",
       "      <td>0.095001</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>76.149785</td>\n",
       "      <td>251.785270</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>169.720262</td>\n",
       "      <td>128.468505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>119.059998</td>\n",
       "      <td>119.480003</td>\n",
       "      <td>118.519997</td>\n",
       "      <td>119.190002</td>\n",
       "      <td>119.190002</td>\n",
       "      <td>18142300.0</td>\n",
       "      <td>119.004997</td>\n",
       "      <td>118.509998</td>\n",
       "      <td>0.494999</td>\n",
       "      <td>0.754998</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>105.242738</td>\n",
       "      <td>295.072859</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>292.523886</td>\n",
       "      <td>167.548630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>119.860001</td>\n",
       "      <td>120.430000</td>\n",
       "      <td>119.150002</td>\n",
       "      <td>119.970001</td>\n",
       "      <td>119.970001</td>\n",
       "      <td>22860700.0</td>\n",
       "      <td>119.459999</td>\n",
       "      <td>119.004997</td>\n",
       "      <td>0.455002</td>\n",
       "      <td>0.494999</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>107.967117</td>\n",
       "      <td>284.393161</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>270.367990</td>\n",
       "      <td>152.182933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>119.860001</td>\n",
       "      <td>120.430000</td>\n",
       "      <td>119.150002</td>\n",
       "      <td>119.970001</td>\n",
       "      <td>119.970001</td>\n",
       "      <td>22860700.0</td>\n",
       "      <td>119.459999</td>\n",
       "      <td>119.004997</td>\n",
       "      <td>0.455002</td>\n",
       "      <td>0.494999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.080714</td>\n",
       "      <td>6.603333</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.699998</td>\n",
       "      <td>3.506199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open        High         Low       Close   Adj Close      Volume  \\\n",
       "5002  118.070000  118.320000  116.959999  117.940002  117.940002  25399800.0   \n",
       "4007  118.949997  119.110001  118.099998  119.019997  119.019997  22789100.0   \n",
       "4008  119.059998  119.480003  118.519997  119.190002  119.190002  18142300.0   \n",
       "4009  119.860001  120.430000  119.150002  119.970001  119.970001  22860700.0   \n",
       "5003  119.860001  120.430000  119.150002  119.970001  119.970001  22860700.0   \n",
       "\n",
       "            sma2      sma2_1  sma2_increment  sma2_1_increment  ...  \\\n",
       "5002  117.755001  117.659999        0.095001         -0.590001  ...   \n",
       "4007  118.509998  117.755001        0.754998          0.095001  ...   \n",
       "4008  119.004997  118.509998        0.494999          0.754998  ...   \n",
       "4009  119.459999  119.004997        0.455002          0.494999  ...   \n",
       "5003  119.459999  119.004997        0.455002          0.494999  ...   \n",
       "\n",
       "      disgust_y  anticipation_y    fear_y   trust_y  tb_polarity_y  \\\n",
       "5002       14.0        0.001786  0.000303  0.000922      47.475081   \n",
       "4007       23.0        0.001619  0.000319  0.001047      76.149785   \n",
       "4008       21.0        0.001946  0.000365  0.001304     105.242738   \n",
       "4009       28.0        0.001708  0.000355  0.001266     107.967117   \n",
       "5003        0.0        0.000362  0.000362  0.001086       0.080714   \n",
       "\n",
       "      tb_subjectivity_y  hiv4_positive_y  hiv4_negative_y  hiv4_polarity_y  \\\n",
       "5002         141.259152            648.0            283.0       122.033564   \n",
       "4007         251.785270           1126.0            597.0       169.720262   \n",
       "4008         295.072859           1515.0            606.0       292.523886   \n",
       "4009         284.393161           1381.0            578.0       270.367990   \n",
       "5003           6.603333             21.0             17.0         2.699998   \n",
       "\n",
       "      hiv4_subjectivity_y  \n",
       "5002            73.387608  \n",
       "4007           128.468505  \n",
       "4008           167.548630  \n",
       "4009           152.182933  \n",
       "5003             3.506199  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:26.232462Z",
     "start_time": "2019-04-28T23:36:25.729612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save data with without scaling\n",
    "result.to_csv('OverAllDataset_wo_scaling.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:34.261583Z",
     "start_time": "2019-04-28T23:36:34.243612Z"
    }
   },
   "outputs": [],
   "source": [
    "date= result.date.tolist()\n",
    "target = result.Target.tolist()\n",
    "result.drop(['date','Target'],axis =1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:34.557226Z",
     "start_time": "2019-04-28T23:36:34.539262Z"
    }
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "result = pd.DataFrame(scale.fit_transform(result.values), columns=result.columns, index=result.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:34.794248Z",
     "start_time": "2019-04-28T23:36:34.788235Z"
    }
   },
   "outputs": [],
   "source": [
    "result['date'] = date\n",
    "result['Target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:35.713246Z",
     "start_time": "2019-04-28T23:36:35.022941Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save data with without scaling                   \n",
    "result.to_csv('OverAllDataset_with_scaling.csv',index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:35.739746Z",
     "start_time": "2019-04-28T23:36:35.714838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startDate 2003-04-30 00:00:00\n",
      "endDate 2019-04-04 00:00:00\n",
      "shape (5004, 79)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "getStartEndDateShape(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:37.232872Z",
     "start_time": "2019-04-28T23:36:37.219925Z"
    }
   },
   "outputs": [],
   "source": [
    "train = result[result['date'] < pd.to_datetime('2018/06/01')]\n",
    "test = result[result['date'] >= pd.to_datetime('2018/06/01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:38.547439Z",
     "start_time": "2019-04-28T23:36:38.542452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4696, 79)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:41.819819Z",
     "start_time": "2019-04-28T23:36:41.814855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 79)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:48:54.091252Z",
     "start_time": "2019-04-27T16:48:53.425558Z"
    }
   },
   "outputs": [],
   "source": [
    "train.to_csv('train_tw_nw_fi.csv',index=False)\n",
    "test.to_csv('test_tw_nw_fi.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T02:52:08.923857Z",
     "start_time": "2019-04-10T02:52:08.920847Z"
    }
   },
   "source": [
    "# NEWS RandomForest- NonScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:53.842279Z",
     "start_time": "2019-04-28T23:36:53.828317Z"
    }
   },
   "outputs": [],
   "source": [
    "featureDF_nw.date = pd.to_datetime(featureDF_nw.date)\n",
    "targtWithDateForJoin.date = pd.to_datetime(targtWithDateForJoin.date)\n",
    "\n",
    "result =pd.merge(featureDF_nw, targtWithDateForJoin, how='left', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:54.170346Z",
     "start_time": "2019-04-28T23:36:54.165361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4020, 25)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:54.507064Z",
     "start_time": "2019-04-28T23:36:54.503075Z"
    }
   },
   "outputs": [],
   "source": [
    "#mn.matrix(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:54.899003Z",
     "start_time": "2019-04-28T23:36:54.892023Z"
    }
   },
   "outputs": [],
   "source": [
    "result.sort_values(by='date',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:55.208216Z",
     "start_time": "2019-04-28T23:36:55.203250Z"
    }
   },
   "outputs": [],
   "source": [
    "result['target'] = result['target'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:55.441063Z",
     "start_time": "2019-04-28T23:36:55.437078Z"
    }
   },
   "outputs": [],
   "source": [
    "#mn.matrix(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:55.812946Z",
     "start_time": "2019-04-28T23:36:55.713228Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "#train and test split\n",
    "train_nw = result[result['date'] < pd.to_datetime('2018/06/01')]\n",
    "test_nw = result[result['date'] >= pd.to_datetime('2018/06/01')]\n",
    "\n",
    "train_nw_y = train_nw['target']\n",
    "test_nw_y = test_nw['target']\n",
    "\n",
    "train_nw.drop(['date','target'],axis=1,inplace=True)\n",
    "test_nw.drop(['date','target'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:56.617698Z",
     "start_time": "2019-04-28T23:36:56.612713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nw (3806, 23) test_nw (214, 23) len(train_nw_y) 3806 len(test_nw_y) 214\n"
     ]
    }
   ],
   "source": [
    "print('train_nw',train_nw.shape,'test_nw',test_nw.shape,'len(train_nw_y)',len(train_nw_y),'len(test_nw_y)',len(test_nw_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:57.258373Z",
     "start_time": "2019-04-28T23:36:57.253387Z"
    }
   },
   "outputs": [],
   "source": [
    "def NaivePredition(y_test):\n",
    "    \n",
    "    y_testCheck = y_test.copy()\n",
    "    y_pred = list()\n",
    "    \n",
    "    for counter in range(len(y_testCheck)-1):\n",
    "        y_pred.append(y_testCheck[counter])\n",
    "    \n",
    "    y_testCheck = y_testCheck[1:]\n",
    "    print ('Model accuracy = %.3f' % accuracy_score(y_pred,y_testCheck))\n",
    "\n",
    "    print('classification_score\\n',classification_report(y_pred, y_testCheck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:36:58.292316Z",
     "start_time": "2019-04-28T23:36:58.283364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.756\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.74      0.74       100\n",
      "         1.0       0.77      0.77      0.77       113\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       213\n",
      "   macro avg       0.75      0.75      0.75       213\n",
      "weighted avg       0.76      0.76      0.76       213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaivePredition(list(test_nw_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:41:26.158846Z",
     "start_time": "2019-04-28T23:41:26.152892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Naive Bayes for Baseline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "def NaiveBayes(train_features , train_labels, test_features,test_labels):\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(train_features, train_labels).predict(test_features)\n",
    "    print('accuracy_score',accuracy_score(y_pred, test_labels))\n",
    "    print('classification_score\\n',classification_report(y_pred, test_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:45:27.712738Z",
     "start_time": "2019-04-28T23:45:27.708717Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotImportanceOfFeature(features,clf):\n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)\n",
    "\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:45:27.968697Z",
     "start_time": "2019-04-28T23:45:27.962711Z"
    }
   },
   "outputs": [],
   "source": [
    "def corelationPlot (df_):\n",
    "    corr = df_.corr()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    fig.colorbar(cax)\n",
    "    ticks = np.arange(0,len(df_.columns),1)\n",
    "    ax.set_xticks(ticks)\n",
    "    plt.xticks(rotation=90)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_xticklabels(df_.columns)\n",
    "    ax.set_yticklabels(df_.columns)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:45:28.849533Z",
     "start_time": "2019-04-28T23:45:28.842579Z"
    }
   },
   "outputs": [],
   "source": [
    "def vif_RemoveHiglyCorelatedFeatures(_df,_dfTest,corPlot = False):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF Factor\"] = [variance_inflation_factor(_df.values, i) for i in range(_df.values.shape[1])]\n",
    "    vif.round(1)\n",
    "    while max(vif[\"VIF Factor\"])>10:\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"VIF Factor\"] = [variance_inflation_factor(_df.values, i) for i in range(_df.values.shape[1])]\n",
    "        vif.round(1)\n",
    "        dropCol = [_df.columns[np.argmax(vif[\"VIF Factor\"])]]\n",
    "        _df.drop(columns=dropCol, inplace=True)\n",
    "        _dfTest.drop(columns=dropCol, inplace=True)\n",
    "        if corPlot:\n",
    "            corelationPlot (_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:48:58.524301Z",
     "start_time": "2019-04-27T16:48:56.951241Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "vif_RemoveHiglyCorelatedFeatures(train_nw,test_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:48:58.531308Z",
     "start_time": "2019-04-27T16:48:58.524301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nw (3806, 15) test_nw (214, 15) len(train_nw_y) 3806 len(test_nw_y) 214\n"
     ]
    }
   ],
   "source": [
    "print('train_nw',train_nw.shape,'test_nw',test_nw.shape,'len(train_nw_y)',len(train_nw_y),'len(test_nw_y)',len(test_nw_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:57:16.865546Z",
     "start_time": "2019-04-28T23:57:16.859563Z"
    }
   },
   "outputs": [],
   "source": [
    "def cCMatrixAccRF(train_features , train_labels, test_features,test_labels, features, dispImpOfFeature = False):\n",
    "#         train_features, test_features, train_labels, test_labels= model_selection.train_test_split( featureDF , targetValue, test_size=0.1, random_state=0)\n",
    "\n",
    "        rf_model =RandomForestClassifier(n_estimators=5000, max_depth=4,random_state=0)\n",
    "        rf_model.fit(train_features, train_labels)\n",
    "        y_predicted=rf_model.predict(test_features)\n",
    "        print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++' )\n",
    "        \n",
    "        if dispImpOfFeature:\n",
    "            plotImportanceOfFeature(features, rf_model)\n",
    "        print('confusion_matrix',confusion_matrix(y_true=test_labels, y_pred=y_predicted))\n",
    "        print('number of datapoints in Up Class', test_labels.value_counts()[1])\n",
    "        print('number of datapoints in Down Class', test_labels.value_counts()[0])\n",
    "        print('accuracy_score',accuracy_score(y_predicted, test_labels))\n",
    "        print('classification_score\\n',classification_report(y_predicted, test_labels))\n",
    "        print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "#         return rf_model.predict(train_features),rf_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:48:58.551254Z",
     "start_time": "2019-04-27T16:48:58.544271Z"
    }
   },
   "outputs": [],
   "source": [
    "def cCMatrixAccAdaboost(train_features , train_labels, test_features,test_labels):\n",
    "#         train_features, test_features, train_labels, test_labels= model_selection.train_test_split( featureDF , targetValue, test_size=0.1, random_state=0)\n",
    "\n",
    "        abc_model =AdaBoostClassifier(n_estimators=5000, random_state=0)\n",
    "        abc_model.fit(train_features, train_labels)\n",
    "        y_predicted=abc_model.predict(test_features)\n",
    "        print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++' )\n",
    "        \n",
    "        print('confusion_matrix',confusion_matrix(y_true=test_labels, y_pred=y_predicted))\n",
    "        print('number of datapoints in Up Class', test_labels.value_counts()[1])\n",
    "        print('number of datapoints in Down Class', test_labels.value_counts()[0])\n",
    "        print('accuracy_score',accuracy_score(y_predicted, test_labels))\n",
    "        print('classification_score\\n',classification_report(y_predicted, test_labels))\n",
    "        print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:48:58.576185Z",
     "start_time": "2019-04-27T16:48:58.553248Z"
    }
   },
   "outputs": [],
   "source": [
    "def cCMatrixAccGradientTreeBosting(train_features , train_labels, test_features,test_labels):\n",
    "#         train_features, test_features, train_labels, test_labels= model_selection.train_test_split( featureDF , targetValue, test_size=0.1, random_state=0)\n",
    "\n",
    "        gbc_model =GradientBoostingClassifier(n_estimators=5000, learning_rate=1.0, max_depth=4,random_state=0)\n",
    "        gbc_model.fit(train_features, train_labels)\n",
    "        y_predicted=gbc_model.predict(test_features)\n",
    "        print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++' )\n",
    "        \n",
    "        print('confusion_matrix',confusion_matrix(y_true=test_labels, y_pred=y_predicted))\n",
    "        print('number of datapoints in Up Class', test_labels.value_counts()[1])\n",
    "        print('number of datapoints in Down Class', test_labels.value_counts()[0])\n",
    "        print('accuracy_score',accuracy_score(y_predicted, test_labels))\n",
    "        print('classification_score\\n',classification_report(y_predicted, test_labels))\n",
    "        print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:48:58.585162Z",
     "start_time": "2019-04-27T16:48:58.578181Z"
    }
   },
   "outputs": [],
   "source": [
    "def cCMatrixAccXGB(X_train , y_train, X_test,y_test):\n",
    "    \n",
    "    regressor = xgb.XGBRegressor(gamma=0.0,n_estimators=150,base_score=0.7,colsample_bytree=1,learning_rate=0.01)\n",
    "\n",
    "    xgbModel = regressor.fit(X_train,y_train)\n",
    "\n",
    "    y_predicted = xgbModel.predict(X_test)\n",
    "    y_predicted_binary = [1 if yp >=0.5 else 0 for yp in y_predicted] # (y_predicted > 0.5)\n",
    "\n",
    "    print ('Model accuracy = %.3f' % accuracy_score(y_test,y_predicted_binary))\n",
    "\n",
    "    print('classification_score\\n',classification_report(y_test, y_predicted_binary))\n",
    "#     return y_predicted_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:48:58.599125Z",
     "start_time": "2019-04-27T16:48:58.587157Z"
    }
   },
   "outputs": [],
   "source": [
    "def cCMatrixAccVotingClasifier(train_features , train_labels, test_features,test_labels):\n",
    "\n",
    "        rf_model =RandomForestClassifier(n_estimators=5000, max_depth=4,random_state=0)\n",
    "        abc_model =AdaBoostClassifier(n_estimators=5000, random_state=0)\n",
    "        gbc_model =GradientBoostingClassifier(n_estimators=5000, learning_rate=1.0, max_depth=4,random_state=0)\n",
    "        lr_model = LogisticRegression(solver='lbfgs', multi_class='ovr',random_state=1)\n",
    "        gnb_model = GaussianNB()\n",
    "        \n",
    "        eclf = VotingClassifier(estimators=[('lr', lr_model), ('rf', rf_model), ('gnb', gnb_model), ('abc', abc_model), ('gbc', gbc_model)], voting='soft')\n",
    "        \n",
    "        for clf, label in zip([lr_model, rf_model, gnb_model,abc_model,gbc_model, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'AdaBoostClassifier','GradientBoostingClassifier','Ensemble']):\n",
    "            scores = cross_val_score(clf, train_features, train_labels, cv=5, scoring='accuracy')\n",
    "            print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:48:58.771667Z",
     "start_time": "2019-04-27T16:48:58.766679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nw (3806, 15) test_nw (214, 15) len(train_nw_y) 3806 len(test_nw_y) 214\n"
     ]
    }
   ],
   "source": [
    "print('train_nw',train_nw.shape,'test_nw',test_nw.shape,'len(train_nw_y)',len(train_nw_y),'len(test_nw_y)',len(test_nw_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:42:22.590614Z",
     "start_time": "2019-04-28T23:42:22.575653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.49065420560747663\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.05      0.26      0.08        19\n",
      "         1.0       0.88      0.51      0.65       195\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       214\n",
      "   macro avg       0.46      0.39      0.37       214\n",
      "weighted avg       0.80      0.49      0.60       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayes(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:49:08.649757Z",
     "start_time": "2019-04-27T16:48:59.009030Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[  7  93]\n",
      " [  7 107]]\n",
      "number of datapoints in Up Class 114\n",
      "number of datapoints in Down Class 100\n",
      "accuracy_score 0.5327102803738317\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.07      0.50      0.12        14\n",
      "         1.0       0.94      0.54      0.68       200\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       214\n",
      "   macro avg       0.50      0.52      0.40       214\n",
      "weighted avg       0.88      0.53      0.64       214\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "features = list(train_nw.columns)\n",
    "cCMatrixAccRF(train_nw , train_nw_y, test_nw,test_nw_y, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:49:24.960792Z",
     "start_time": "2019-04-27T16:49:08.651753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[44 56]\n",
      " [50 64]]\n",
      "number of datapoints in Up Class 114\n",
      "number of datapoints in Down Class 100\n",
      "accuracy_score 0.5046728971962616\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.47      0.45        94\n",
      "         1.0       0.56      0.53      0.55       120\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       214\n",
      "   macro avg       0.50      0.50      0.50       214\n",
      "weighted avg       0.51      0.50      0.51       214\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccAdaboost(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:49:29.620833Z",
     "start_time": "2019-04-27T16:49:24.963784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[47 53]\n",
      " [54 60]]\n",
      "number of datapoints in Up Class 114\n",
      "number of datapoints in Down Class 100\n",
      "accuracy_score 0.5\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.47      0.47       101\n",
      "         1.0       0.53      0.53      0.53       113\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       214\n",
      "   macro avg       0.50      0.50      0.50       214\n",
      "weighted avg       0.50      0.50      0.50       214\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccGradientTreeBosting(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:53:53.614309Z",
     "start_time": "2019-04-27T16:49:29.622828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51 (+/- 0.00) [Logistic Regression]\n",
      "Accuracy: 0.51 (+/- 0.00) [Random Forest]\n",
      "Accuracy: 0.51 (+/- 0.01) [naive Bayes]\n",
      "Accuracy: 0.50 (+/- 0.02) [AdaBoostClassifier]\n",
      "Accuracy: 0.51 (+/- 0.01) [GradientBoostingClassifier]\n",
      "Accuracy: 0.51 (+/- 0.01) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccVotingClasifier(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:53:55.168926Z",
     "start_time": "2019-04-27T16:53:53.616895Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.523\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      0.01      0.02       100\n",
      "         1.0       0.53      0.97      0.69       114\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       214\n",
      "   macro avg       0.39      0.49      0.35       214\n",
      "weighted avg       0.40      0.52      0.37       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccXGB(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWS RandomForest- Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:45:06.458917Z",
     "start_time": "2019-04-28T23:45:06.445953Z"
    }
   },
   "outputs": [],
   "source": [
    "featureDF_nw.date = pd.to_datetime(featureDF_nw.date)\n",
    "targtWithDateForJoin.date = pd.to_datetime(targtWithDateForJoin.date)\n",
    "result =pd.merge(featureDF_nw, targtWithDateForJoin, how='left', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:45:07.267448Z",
     "start_time": "2019-04-28T23:45:07.259477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4020, 25)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values(by='date',inplace=True) \n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:45:07.692139Z",
     "start_time": "2019-04-28T23:45:07.687151Z"
    }
   },
   "outputs": [],
   "source": [
    "result['target'] = result['target'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:45:08.449239Z",
     "start_time": "2019-04-28T23:45:08.347511Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "#train and test split\n",
    "train_nw = result[result['date'] < pd.to_datetime('2018/06/01')]\n",
    "test_nw = result[result['date'] >= pd.to_datetime('2018/06/01')]\n",
    "\n",
    "train_nw_y = train_nw['target']\n",
    "test_nw_y = test_nw['target']\n",
    "\n",
    "train_nw.drop(['date','target'],axis=1,inplace=True)\n",
    "test_nw.drop(['date','target'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:45:12.595888Z",
     "start_time": "2019-04-28T23:45:12.590886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nw (3806, 23) test_nw (214, 23) len(train_nw_y) 3806 len(test_nw_y) 214\n"
     ]
    }
   ],
   "source": [
    "print('train_nw',train_nw.shape,'test_nw',test_nw.shape,'len(train_nw_y)',len(train_nw_y),'len(test_nw_y)',len(test_nw_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:45:13.213736Z",
     "start_time": "2019-04-28T23:45:13.204756Z"
    }
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "train_nw = pd.DataFrame(scale.fit_transform(train_nw.values), columns=train_nw.columns, index=train_nw.index)\n",
    "scale = StandardScaler()\n",
    "test_nw = pd.DataFrame(scale.fit_transform(test_nw.values), columns=test_nw.columns, index=test_nw.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:45:37.151900Z",
     "start_time": "2019-04-28T23:45:36.563475Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nw (3806, 18) test_nw (214, 18) len(train_nw_y) 3806 len(test_nw_y) 214\n"
     ]
    }
   ],
   "source": [
    "vif_RemoveHiglyCorelatedFeatures(train_nw,test_nw)\n",
    "print('train_nw',train_nw.shape,'test_nw',test_nw.shape,'len(train_nw_y)',len(train_nw_y),'len(test_nw_y)',len(test_nw_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:45:51.788813Z",
     "start_time": "2019-04-28T23:45:51.775836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.45794392523364486\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.30      0.39      0.34        76\n",
      "         1.0       0.60      0.49      0.54       138\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       214\n",
      "   macro avg       0.45      0.44      0.44       214\n",
      "weighted avg       0.49      0.46      0.47       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayes(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:54:07.064088Z",
     "start_time": "2019-04-27T16:53:55.902063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[13 87]\n",
      " [18 96]]\n",
      "number of datapoints in Up Class 114\n",
      "number of datapoints in Down Class 100\n",
      "accuracy_score 0.5093457943925234\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.13      0.42      0.20        31\n",
      "         1.0       0.84      0.52      0.65       183\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       214\n",
      "   macro avg       0.49      0.47      0.42       214\n",
      "weighted avg       0.74      0.51      0.58       214\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "features = list(train_nw.columns)\n",
    "temp=cCMatrixAccRF(train_nw , train_nw_y, test_nw,test_nw_y, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:54:26.540788Z",
     "start_time": "2019-04-27T16:54:07.064977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[41 59]\n",
      " [53 61]]\n",
      "number of datapoints in Up Class 114\n",
      "number of datapoints in Down Class 100\n",
      "accuracy_score 0.4766355140186916\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.44      0.42        94\n",
      "         1.0       0.54      0.51      0.52       120\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       214\n",
      "   macro avg       0.47      0.47      0.47       214\n",
      "weighted avg       0.48      0.48      0.48       214\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccAdaboost(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:54:31.348250Z",
     "start_time": "2019-04-27T16:54:26.542782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[50 50]\n",
      " [57 57]]\n",
      "number of datapoints in Up Class 114\n",
      "number of datapoints in Down Class 100\n",
      "accuracy_score 0.5\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.47      0.48       107\n",
      "         1.0       0.50      0.53      0.52       107\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       214\n",
      "   macro avg       0.50      0.50      0.50       214\n",
      "weighted avg       0.50      0.50      0.50       214\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccGradientTreeBosting(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:59:44.416290Z",
     "start_time": "2019-04-27T16:54:31.349247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51 (+/- 0.00) [Logistic Regression]\n",
      "Accuracy: 0.51 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.51 (+/- 0.02) [naive Bayes]\n",
      "Accuracy: 0.51 (+/- 0.01) [AdaBoostClassifier]\n",
      "Accuracy: 0.52 (+/- 0.01) [GradientBoostingClassifier]\n",
      "Accuracy: 0.53 (+/- 0.01) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccVotingClasifier(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:59:45.910348Z",
     "start_time": "2019-04-27T16:59:44.417261Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.523\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      0.01      0.02       100\n",
      "         1.0       0.53      0.97      0.69       114\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       214\n",
      "   macro avg       0.39      0.49      0.35       214\n",
      "weighted avg       0.40      0.52      0.37       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccXGB(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter RandomForest- NonScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:48:54.033878Z",
     "start_time": "2019-04-28T23:48:54.027880Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDataset(result):\n",
    "    #train and test split\n",
    "    train_ = result[result['date'] < pd.to_datetime('2018/06/01')]\n",
    "    test_ = result[result['date'] >= pd.to_datetime('2018/06/01')]\n",
    "\n",
    "    train_y = train_['target']\n",
    "    test_y = test_['target']\n",
    "\n",
    "    train_.drop(['date','target'],axis=1,inplace=True)\n",
    "    test_.drop(['date','target'],axis=1,inplace=True)\n",
    "    return train_, test_, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:48:54.803313Z",
     "start_time": "2019-04-28T23:48:54.696568Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "featureDF_tw.date = pd.to_datetime(featureDF_tw.date)\n",
    "targtWithDateForJoin.date = pd.to_datetime(targtWithDateForJoin.date)\n",
    "\n",
    "result =pd.merge(featureDF_tw, targtWithDateForJoin, how='left', on='date')\n",
    "\n",
    "result.shape\n",
    "\n",
    "#mn.matrix(result)\n",
    "\n",
    "result.sort_values(by='date',inplace=True) \n",
    "\n",
    "result['target'] = result['target'].ffill()\n",
    "\n",
    "#mn.matrix(result)\n",
    "\n",
    "\n",
    "train_tw, test_tw, train_tw_y, test_tw_y = getDataset(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:00:06.730306Z",
     "start_time": "2019-04-27T17:00:06.721329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.811\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.79      0.79       139\n",
      "         1.0       0.83      0.83      0.83       168\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       307\n",
      "   macro avg       0.81      0.81      0.81       307\n",
      "weighted avg       0.81      0.81      0.81       307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaivePredition(list(test_tw_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:49:31.212388Z",
     "start_time": "2019-04-28T23:49:31.198400Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.5324675324675324\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.06      0.38      0.10        21\n",
      "         1.0       0.92      0.54      0.68       287\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       308\n",
      "   macro avg       0.49      0.46      0.39       308\n",
      "weighted avg       0.86      0.53      0.64       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayes(train_tw , train_tw_y, test_tw,test_tw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:00:06.958696Z",
     "start_time": "2019-04-27T17:00:06.954708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nw (3806, 18) test_nw (214, 18) len(train_nw_y) 3806 len(test_nw_y) 214\n"
     ]
    }
   ],
   "source": [
    "print('train_nw',train_nw.shape,'test_nw',test_nw.shape,'len(train_nw_y)',len(train_nw_y),'len(test_nw_y)',len(test_nw_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:00:07.292828Z",
     "start_time": "2019-04-27T17:00:07.229970Z"
    }
   },
   "outputs": [],
   "source": [
    "vif_RemoveHiglyCorelatedFeatures(train_nw,test_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:00:07.502243Z",
     "start_time": "2019-04-27T17:00:07.498252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nw (3806, 18) test_nw (214, 18) len(train_nw_y) 3806 len(test_nw_y) 214\n"
     ]
    }
   ],
   "source": [
    "print('train_nw',train_nw.shape,'test_nw',test_nw.shape,'len(train_nw_y)',len(train_nw_y),'len(test_nw_y)',len(test_nw_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:00:19.767665Z",
     "start_time": "2019-04-27T17:00:07.938171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[13 87]\n",
      " [18 96]]\n",
      "number of datapoints in Up Class 114\n",
      "number of datapoints in Down Class 100\n",
      "accuracy_score 0.5093457943925234\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.13      0.42      0.20        31\n",
      "         1.0       0.84      0.52      0.65       183\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       214\n",
      "   macro avg       0.49      0.47      0.42       214\n",
      "weighted avg       0.74      0.51      0.58       214\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "features = list(train_nw.columns)\n",
    "cCMatrixAccRF(train_nw , train_nw_y, test_nw,test_nw_y, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:00:41.083367Z",
     "start_time": "2019-04-27T17:00:19.767665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[41 59]\n",
      " [53 61]]\n",
      "number of datapoints in Up Class 114\n",
      "number of datapoints in Down Class 100\n",
      "accuracy_score 0.4766355140186916\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.44      0.42        94\n",
      "         1.0       0.54      0.51      0.52       120\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       214\n",
      "   macro avg       0.47      0.47      0.47       214\n",
      "weighted avg       0.48      0.48      0.48       214\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccAdaboost(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:00:46.330517Z",
     "start_time": "2019-04-27T17:00:41.085329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[50 50]\n",
      " [57 57]]\n",
      "number of datapoints in Up Class 114\n",
      "number of datapoints in Down Class 100\n",
      "accuracy_score 0.5\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.47      0.48       107\n",
      "         1.0       0.50      0.53      0.52       107\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       214\n",
      "   macro avg       0.50      0.50      0.50       214\n",
      "weighted avg       0.50      0.50      0.50       214\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccGradientTreeBosting(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:06:19.070210Z",
     "start_time": "2019-04-27T17:00:46.332498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51 (+/- 0.00) [Logistic Regression]\n",
      "Accuracy: 0.51 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.51 (+/- 0.02) [naive Bayes]\n",
      "Accuracy: 0.51 (+/- 0.01) [AdaBoostClassifier]\n",
      "Accuracy: 0.52 (+/- 0.01) [GradientBoostingClassifier]\n",
      "Accuracy: 0.53 (+/- 0.01) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccVotingClasifier(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:06:20.711683Z",
     "start_time": "2019-04-27T17:06:19.072169Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.523\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      0.01      0.02       100\n",
      "         1.0       0.53      0.97      0.69       114\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       214\n",
      "   macro avg       0.39      0.49      0.35       214\n",
      "weighted avg       0.40      0.52      0.37       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccXGB(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter RandomForest- Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:50:38.651784Z",
     "start_time": "2019-04-28T23:50:38.645818Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDataset(result):\n",
    "    #train and test split\n",
    "    train_tw = result[result['date'] < pd.to_datetime('2018/06/01')]\n",
    "    test_tw = result[result['date'] >= pd.to_datetime('2018/06/01')]\n",
    "\n",
    "    train_tw_y = train_tw['target']\n",
    "    test_tw_y = test_tw['target']\n",
    "\n",
    "    train_tw.drop(['date','target'],axis=1,inplace=True)\n",
    "    test_tw.drop(['date','target'],axis=1,inplace=True)\n",
    "    return train_tw, test_tw, train_tw_y, test_tw_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:50:39.913561Z",
     "start_time": "2019-04-28T23:50:39.808807Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "featureDF_tw.date = pd.to_datetime(featureDF_tw.date)\n",
    "targtWithDateForJoin.date = pd.to_datetime(targtWithDateForJoin.date)\n",
    "\n",
    "result =pd.merge(featureDF_tw, targtWithDateForJoin, how='left', on='date')\n",
    "\n",
    "result.shape\n",
    "\n",
    "result.sort_values(by='date',inplace=True) \n",
    "\n",
    "result['target'] = result['target'].ffill()\n",
    "\n",
    "train_tw, test_tw, train_tw_y, test_tw_y = getDataset(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:50:40.719977Z",
     "start_time": "2019-04-28T23:50:40.621236Z"
    }
   },
   "outputs": [],
   "source": [
    "train_nw, test_nw, train_nw_y, test_nw_y = getDataset(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:50:43.116689Z",
     "start_time": "2019-04-28T23:50:43.109699Z"
    }
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "train_tw = pd.DataFrame(scale.fit_transform(train_tw.values), columns=train_tw.columns, index=train_tw.index)\n",
    "scale = StandardScaler()\n",
    "test_tw = pd.DataFrame(scale.fit_transform(test_tw.values), columns=test_tw.columns, index=test_tw.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:50:43.693068Z",
     "start_time": "2019-04-28T23:50:43.688083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tw (1118, 24) test_tw (308, 24) len(train_tw_y) 1118 len(test_tw_y) 308\n"
     ]
    }
   ],
   "source": [
    "print('train_tw',train_tw.shape,'test_tw',test_tw.shape,'len(train_tw_y)',len(train_tw_y),'len(test_tw_y)',len(test_tw_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:50:44.987184Z",
     "start_time": "2019-04-28T23:50:44.552346Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tw (1118, 12) test_tw (308, 12) len(train_tw_y) 1118 len(test_tw_y) 308\n"
     ]
    }
   ],
   "source": [
    "vif_RemoveHiglyCorelatedFeatures(train_tw,test_tw)\n",
    "print('train_tw',train_tw.shape,'test_tw',test_tw.shape,'len(train_tw_y)',len(train_tw_y),'len(test_tw_y)',len(test_tw_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:50:52.297285Z",
     "start_time": "2019-04-28T23:50:52.286311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.5422077922077922\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.49      0.41       100\n",
      "         1.0       0.70      0.57      0.63       208\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       308\n",
      "   macro avg       0.53      0.53      0.52       308\n",
      "weighted avg       0.59      0.54      0.56       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayes(train_tw , train_tw_y, test_tw,test_tw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:06:28.127278Z",
     "start_time": "2019-04-27T17:06:21.471834Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[ 28 111]\n",
      " [ 27 142]]\n",
      "number of datapoints in Up Class 169\n",
      "number of datapoints in Down Class 139\n",
      "accuracy_score 0.551948051948052\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.51      0.29        55\n",
      "         1.0       0.84      0.56      0.67       253\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       308\n",
      "   macro avg       0.52      0.54      0.48       308\n",
      "weighted avg       0.73      0.55      0.60       308\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "features = list(train_tw.columns)\n",
    "temp = cCMatrixAccRF(train_tw , train_tw_y, test_tw,test_tw_y, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:06:37.298206Z",
     "start_time": "2019-04-27T17:06:28.127278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[49 90]\n",
      " [70 99]]\n",
      "number of datapoints in Up Class 169\n",
      "number of datapoints in Down Class 139\n",
      "accuracy_score 0.4805194805194805\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.41      0.38       119\n",
      "         1.0       0.59      0.52      0.55       189\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       308\n",
      "   macro avg       0.47      0.47      0.47       308\n",
      "weighted avg       0.50      0.48      0.49       308\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccAdaboost(train_tw , train_tw_y, test_tw,test_tw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:06:42.357741Z",
     "start_time": "2019-04-27T17:06:37.299203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[ 64  75]\n",
      " [ 69 100]]\n",
      "number of datapoints in Up Class 169\n",
      "number of datapoints in Down Class 139\n",
      "accuracy_score 0.5324675324675324\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.48      0.47       133\n",
      "         1.0       0.59      0.57      0.58       175\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       308\n",
      "   macro avg       0.53      0.53      0.53       308\n",
      "weighted avg       0.54      0.53      0.53       308\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccGradientTreeBosting(train_tw , train_tw_y, test_tw,test_tw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:09:41.097938Z",
     "start_time": "2019-04-27T17:06:42.357741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54 (+/- 0.02) [Logistic Regression]\n",
      "Accuracy: 0.53 (+/- 0.03) [Random Forest]\n",
      "Accuracy: 0.53 (+/- 0.04) [naive Bayes]\n",
      "Accuracy: 0.51 (+/- 0.02) [AdaBoostClassifier]\n",
      "Accuracy: 0.49 (+/- 0.02) [GradientBoostingClassifier]\n",
      "Accuracy: 0.53 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccVotingClasifier(train_tw , train_tw_y, test_tw,test_tw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:10:51.914598Z",
     "start_time": "2019-04-27T17:10:50.746126Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.526\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.39      0.09      0.15       139\n",
      "         1.0       0.54      0.88      0.67       169\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       308\n",
      "   macro avg       0.47      0.49      0.41       308\n",
      "weighted avg       0.48      0.53      0.44       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccXGB(train_tw , train_tw_y, test_tw,test_tw_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Indicator RandomForest- NonScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:52:24.154895Z",
     "start_time": "2019-04-28T23:52:24.148895Z"
    }
   },
   "outputs": [],
   "source": [
    "fi_df_copy = targetDF_.copy()\n",
    "fi_df_copy.rename(columns={'Target':'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:52:24.666404Z",
     "start_time": "2019-04-28T23:52:24.661419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'sma2', 'sma2_1',\n",
       "       'sma2_increment', 'sma2_1_increment', 'vol_increment',\n",
       "       'vol_rel_increment', 'open_1', 'open_incr', 'open', 'ma7', 'ma21',\n",
       "       '26ema', '12ema', 'MACD', '30 Day MA', '30 Day STD', 'upper_band',\n",
       "       'lower_band', 'ema', 'momentum', 'log_momentum', 'fft', 'absolute',\n",
       "       'angle', 'date', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:52:26.558998Z",
     "start_time": "2019-04-28T23:52:26.466219Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train_fi, test_fi, train_fi_y, test_fi_y = getDataset(fi_df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:52:30.023603Z",
     "start_time": "2019-04-28T23:52:30.019587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_fi (3799, 30) test_fi (211, 30) len(train_fi_y) 3799 len(test_fi_y) 211\n"
     ]
    }
   ],
   "source": [
    "print('train_fi',train_fi.shape,'test_fi',test_fi.shape,'len(train_fi_y)',len(train_fi_y),'len(test_fi_y)',len(test_fi_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:52:34.608737Z",
     "start_time": "2019-04-28T23:52:30.461850Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:181: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "vif_RemoveHiglyCorelatedFeatures(train_fi,test_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:11:10.201770Z",
     "start_time": "2019-04-27T17:11:10.191243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.724\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69        95\n",
      "           1       0.75      0.75      0.75       115\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       210\n",
      "   macro avg       0.72      0.72      0.72       210\n",
      "weighted avg       0.72      0.72      0.72       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaivePredition(list(test_fi_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:52:51.783414Z",
     "start_time": "2019-04-28T23:52:51.771421Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.5308056872037915\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.17      0.02         6\n",
      "           1       0.96      0.54      0.69       205\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       211\n",
      "   macro avg       0.48      0.35      0.36       211\n",
      "weighted avg       0.93      0.53      0.67       211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayes(train_fi , train_fi_y, test_fi,test_fi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:11:10.208751Z",
     "start_time": "2019-04-27T17:11:10.203765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_fi (3799, 9) test_fi (211, 9) len(train_fi_y) 3799 len(test_fi_y) 211\n"
     ]
    }
   ],
   "source": [
    "print('train_fi',train_fi.shape,'test_fi',test_fi.shape,'len(train_fi_y)',len(train_fi_y),'len(test_fi_y)',len(test_fi_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:11:17.083916Z",
     "start_time": "2019-04-27T17:11:10.210748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[  4 135]\n",
      " [  2 167]]\n",
      "number of datapoints in Up Class 169\n",
      "number of datapoints in Down Class 139\n",
      "accuracy_score 0.5551948051948052\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.03      0.67      0.06         6\n",
      "         1.0       0.99      0.55      0.71       302\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       308\n",
      "   macro avg       0.51      0.61      0.38       308\n",
      "weighted avg       0.97      0.56      0.70       308\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "features = list(train_nw.columns)\n",
    "cCMatrixAccRF(train_nw , train_nw_y, test_nw,test_nw_y, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:11:30.889139Z",
     "start_time": "2019-04-27T17:11:17.084915Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[ 35 104]\n",
      " [ 54 115]]\n",
      "number of datapoints in Up Class 169\n",
      "number of datapoints in Down Class 139\n",
      "accuracy_score 0.487012987012987\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      0.39      0.31        89\n",
      "         1.0       0.68      0.53      0.59       219\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       308\n",
      "   macro avg       0.47      0.46      0.45       308\n",
      "weighted avg       0.56      0.49      0.51       308\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccAdaboost(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:11:36.325798Z",
     "start_time": "2019-04-27T17:11:30.891133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[ 44  95]\n",
      " [ 54 115]]\n",
      "number of datapoints in Up Class 169\n",
      "number of datapoints in Down Class 139\n",
      "accuracy_score 0.5162337662337663\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.32      0.45      0.37        98\n",
      "         1.0       0.68      0.55      0.61       210\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       308\n",
      "   macro avg       0.50      0.50      0.49       308\n",
      "weighted avg       0.56      0.52      0.53       308\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccGradientTreeBosting(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:15:08.780504Z",
     "start_time": "2019-04-27T17:11:36.327811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53 (+/- 0.02) [Logistic Regression]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53 (+/- 0.02) [Random Forest]\n",
      "Accuracy: 0.52 (+/- 0.04) [naive Bayes]\n",
      "Accuracy: 0.52 (+/- 0.03) [AdaBoostClassifier]\n",
      "Accuracy: 0.52 (+/- 0.03) [GradientBoostingClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53 (+/- 0.04) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccVotingClasifier(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:15:10.109055Z",
     "start_time": "2019-04-27T17:15:08.783496Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.536\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.03      0.05       139\n",
      "         1.0       0.54      0.95      0.69       169\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       308\n",
      "   macro avg       0.44      0.49      0.37       308\n",
      "weighted avg       0.45      0.54      0.40       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccXGB(train_nw , train_nw_y, test_nw,test_nw_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Indicator RandomForest- Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:55:50.895591Z",
     "start_time": "2019-04-28T23:55:50.889608Z"
    }
   },
   "outputs": [],
   "source": [
    "fi_df_copy = targetDF_.copy()\n",
    "fi_df_copy.rename(columns={'Target':'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:55:51.216264Z",
     "start_time": "2019-04-28T23:55:51.119492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train_fi, test_fi, train_fi_y, test_fi_y = getDataset(fi_df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:55:51.289297Z",
     "start_time": "2019-04-28T23:55:51.278326Z"
    }
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "train_fi = pd.DataFrame(scale.fit_transform(train_fi.values), columns=train_fi.columns, index=train_fi.index)\n",
    "scale = StandardScaler()\n",
    "test_fi = pd.DataFrame(scale.fit_transform(test_fi.values), columns=test_fi.columns, index=test_fi.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:55:51.447376Z",
     "start_time": "2019-04-28T23:55:51.441401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_fi (3799, 30) test_fi (211, 30) len(train_fi_y) 3799 len(test_fi_y) 211\n"
     ]
    }
   ],
   "source": [
    "print('train_fi',train_fi.shape,'test_fi',test_fi.shape,'len(train_fi_y)',len(train_fi_y),'len(test_fi_y)',len(test_fi_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:55:53.588688Z",
     "start_time": "2019-04-28T23:55:51.628929Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:181: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_fi (3799, 9) test_fi (211, 9) len(train_fi_y) 3799 len(test_fi_y) 211\n"
     ]
    }
   ],
   "source": [
    "vif_RemoveHiglyCorelatedFeatures(train_fi,test_fi)\n",
    "print('train_fi',train_fi.shape,'test_fi',test_fi.shape,'len(train_fi_y)',len(train_fi_y),'len(test_fi_y)',len(test_fi_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:56:06.359485Z",
     "start_time": "2019-04-28T23:56:06.348522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.5545023696682464\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.52      0.27        33\n",
      "           1       0.86      0.56      0.68       178\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       211\n",
      "   macro avg       0.52      0.54      0.47       211\n",
      "weighted avg       0.76      0.55      0.62       211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayes(train_fi , train_fi_y, test_fi,test_fi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T23:57:48.779121Z",
     "start_time": "2019-04-28T23:57:30.017337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[77 18]\n",
      " [33 83]]\n",
      "number of datapoints in Up Class 116\n",
      "number of datapoints in Down Class 95\n",
      "accuracy_score 0.7582938388625592\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75       110\n",
      "           1       0.72      0.82      0.76       101\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       211\n",
      "   macro avg       0.76      0.76      0.76       211\n",
      "weighted avg       0.77      0.76      0.76       211\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "features = list(train_fi.columns)\n",
    "temp = cCMatrixAccRF(train_fi , train_fi_y, test_fi,test_fi_y, features, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:15:52.006465Z",
     "start_time": "2019-04-27T17:15:29.889577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[67 28]\n",
      " [53 63]]\n",
      "number of datapoints in Up Class 116\n",
      "number of datapoints in Down Class 95\n",
      "accuracy_score 0.6161137440758294\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.56      0.62       120\n",
      "           1       0.54      0.69      0.61        91\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       211\n",
      "   macro avg       0.62      0.63      0.62       211\n",
      "weighted avg       0.64      0.62      0.62       211\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccAdaboost(train_fi , train_fi_y, test_fi,test_fi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:15:55.820883Z",
     "start_time": "2019-04-27T17:15:52.006465Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[70 25]\n",
      " [46 70]]\n",
      "number of datapoints in Up Class 116\n",
      "number of datapoints in Down Class 95\n",
      "accuracy_score 0.6635071090047393\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.60      0.66       116\n",
      "           1       0.60      0.74      0.66        95\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       211\n",
      "   macro avg       0.67      0.67      0.66       211\n",
      "weighted avg       0.68      0.66      0.66       211\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccGradientTreeBosting(train_fi , train_fi_y, test_fi,test_fi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:22:01.123828Z",
     "start_time": "2019-04-27T17:15:55.820883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74 (+/- 0.01) [Logistic Regression]\n",
      "Accuracy: 0.71 (+/- 0.02) [Random Forest]\n",
      "Accuracy: 0.55 (+/- 0.04) [naive Bayes]\n",
      "Accuracy: 0.61 (+/- 0.03) [AdaBoostClassifier]\n",
      "Accuracy: 0.65 (+/- 0.02) [GradientBoostingClassifier]\n",
      "Accuracy: 0.67 (+/- 0.03) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccVotingClasifier(train_fi , train_fi_y, test_fi,test_fi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:22:02.598658Z",
     "start_time": "2019-04-27T17:22:01.125822Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.749\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73        95\n",
      "           1       0.78      0.75      0.77       116\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       211\n",
      "   macro avg       0.75      0.75      0.75       211\n",
      "weighted avg       0.75      0.75      0.75       211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cCMatrixAccXGB(train_fi , train_fi_y, test_fi,test_fi_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:33:36.891004Z",
     "start_time": "2019-04-25T22:33:36.887013Z"
    }
   },
   "source": [
    "# Ensemble Tw, News and FI -NonScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T00:05:38.139021Z",
     "start_time": "2019-04-29T00:05:38.025658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent DF: (5004, 79)\n",
      "Train DF: (4696, 79) Test DF: (308, 79)\n"
     ]
    }
   ],
   "source": [
    "nonScaledDataset = pd.read_csv('OverAllDataset_wo_scaling.csv')\n",
    "print('Parent DF:',nonScaledDataset.shape)\n",
    "\n",
    "nonScaledDataset.date = pd.to_datetime(nonScaledDataset.date)\n",
    "\n",
    "trainingData = nonScaledDataset[nonScaledDataset['date'] < pd.to_datetime('2018/06/01')]\n",
    "testingData = nonScaledDataset[nonScaledDataset['date'] >= pd.to_datetime('2018/06/01')]\n",
    "print('Train DF:',trainingData.shape,'Test DF:',testingData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T00:05:38.797492Z",
     "start_time": "2019-04-29T00:05:38.299569Z"
    }
   },
   "outputs": [],
   "source": [
    "trainingData.to_csv('train_ns_tw_nw_fi.csv',index= False)\n",
    "testingData.to_csv('test_ns_tw_nw_fi.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T00:05:38.803371Z",
     "start_time": "2019-04-29T00:05:38.799362Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFeaturesAndTargetRemoveDate(_df):\n",
    "    train_y = _df['Target']\n",
    "    train = _df.drop(['date','Target'],axis =1)\n",
    "    return train, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T00:05:39.003085Z",
     "start_time": "2019-04-29T00:05:38.997103Z"
    }
   },
   "outputs": [],
   "source": [
    "train, train_y = getFeaturesAndTargetRemoveDate(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T00:05:39.312405Z",
     "start_time": "2019-04-29T00:05:39.290490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>sma2</th>\n",
       "      <th>sma2_1</th>\n",
       "      <th>sma2_increment</th>\n",
       "      <th>sma2_1_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>disgust_y</th>\n",
       "      <th>anticipation_y</th>\n",
       "      <th>fear_y</th>\n",
       "      <th>trust_y</th>\n",
       "      <th>tb_polarity_y</th>\n",
       "      <th>tb_subjectivity_y</th>\n",
       "      <th>hiv4_positive_y</th>\n",
       "      <th>hiv4_negative_y</th>\n",
       "      <th>hiv4_polarity_y</th>\n",
       "      <th>hiv4_subjectivity_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.730000</td>\n",
       "      <td>25.879999</td>\n",
       "      <td>25.25</td>\n",
       "      <td>25.570000</td>\n",
       "      <td>18.536860</td>\n",
       "      <td>55566800.0</td>\n",
       "      <td>25.840001</td>\n",
       "      <td>25.670000</td>\n",
       "      <td>0.170001</td>\n",
       "      <td>0.310001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.540001</td>\n",
       "      <td>25.950001</td>\n",
       "      <td>25.34</td>\n",
       "      <td>25.719999</td>\n",
       "      <td>18.645597</td>\n",
       "      <td>42085800.0</td>\n",
       "      <td>25.635001</td>\n",
       "      <td>25.840001</td>\n",
       "      <td>-0.205000</td>\n",
       "      <td>0.170001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open       High    Low      Close  Adj Close      Volume       sma2  \\\n",
       "0  25.730000  25.879999  25.25  25.570000  18.536860  55566800.0  25.840001   \n",
       "1  25.540001  25.950001  25.34  25.719999  18.645597  42085800.0  25.635001   \n",
       "\n",
       "      sma2_1  sma2_increment  sma2_1_increment  ...  disgust_y  \\\n",
       "0  25.670000        0.170001          0.310001  ...        0.0   \n",
       "1  25.840001       -0.205000          0.170001  ...        0.0   \n",
       "\n",
       "   anticipation_y  fear_y  trust_y  tb_polarity_y  tb_subjectivity_y  \\\n",
       "0             0.0     0.0      0.0            0.0                0.0   \n",
       "1             0.0     0.0      0.0            0.0                0.0   \n",
       "\n",
       "   hiv4_positive_y  hiv4_negative_y  hiv4_polarity_y  hiv4_subjectivity_y  \n",
       "0              0.0              0.0              0.0                  0.0  \n",
       "1              0.0              0.0              0.0                  0.0  \n",
       "\n",
       "[2 rows x 77 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T00:05:39.923056Z",
     "start_time": "2019-04-29T00:05:39.918068Z"
    }
   },
   "outputs": [],
   "source": [
    "test, test_y = getFeaturesAndTargetRemoveDate(testingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T00:05:41.335294Z",
     "start_time": "2019-04-29T00:05:41.326324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.811\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.79      0.79       139\n",
      "         1.0       0.83      0.83      0.83       168\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       307\n",
      "   macro avg       0.81      0.81      0.81       307\n",
      "weighted avg       0.81      0.81      0.81       307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaivePredition(list(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T00:05:57.711550Z",
     "start_time": "2019-04-29T00:05:57.691576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.5162337662337663\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.04      0.27      0.07        22\n",
      "         1.0       0.91      0.53      0.67       286\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       308\n",
      "   macro avg       0.47      0.40      0.37       308\n",
      "weighted avg       0.84      0.52      0.63       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayes(train , train_y, test,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:24:15.089892Z",
     "start_time": "2019-04-27T17:24:11.208676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.750\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.68      0.71       139\n",
      "         1.0       0.75      0.81      0.78       169\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       308\n",
      "   macro avg       0.75      0.74      0.75       308\n",
      "weighted avg       0.75      0.75      0.75       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = cCMatrixAccXGB(train , train_y, test,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:24:42.103496Z",
     "start_time": "2019-04-27T17:24:15.091886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[104  35]\n",
      " [ 37 132]]\n",
      "number of datapoints in Up Class 169\n",
      "number of datapoints in Down Class 139\n",
      "accuracy_score 0.7662337662337663\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.74      0.74       141\n",
      "         1.0       0.78      0.79      0.79       167\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       308\n",
      "   macro avg       0.76      0.76      0.76       308\n",
      "weighted avg       0.77      0.77      0.77       308\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "features = list(train.columns)\n",
    "k=cCMatrixAccRF(train , train_y, test,test_y, features,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Tw, News and FI -Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:24:42.234181Z",
     "start_time": "2019-04-27T17:24:42.105500Z"
    }
   },
   "outputs": [],
   "source": [
    "trainingData = pd.read_csv('train_tw_nw_fi.csv')\n",
    "testingData =  pd.read_csv('test_tw_nw_fi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:24:42.241127Z",
     "start_time": "2019-04-27T17:24:42.236142Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFeaturesAndTargetRemoveDate(_df):\n",
    "    train_y = _df['Target']\n",
    "    train = _df.drop(['date','Target'],axis =1)\n",
    "    return train, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:24:42.252125Z",
     "start_time": "2019-04-27T17:24:42.243126Z"
    }
   },
   "outputs": [],
   "source": [
    "train, train_y = getFeaturesAndTargetRemoveDate(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:24:42.262072Z",
     "start_time": "2019-04-27T17:24:42.254094Z"
    }
   },
   "outputs": [],
   "source": [
    "test, test_y = getFeaturesAndTargetRemoveDate(testingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:24:42.289996Z",
     "start_time": "2019-04-27T17:24:42.264068Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>sma2</th>\n",
       "      <th>sma2_1</th>\n",
       "      <th>sma2_increment</th>\n",
       "      <th>sma2_1_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>disgust_y</th>\n",
       "      <th>anticipation_y</th>\n",
       "      <th>fear_y</th>\n",
       "      <th>trust_y</th>\n",
       "      <th>tb_polarity_y</th>\n",
       "      <th>tb_subjectivity_y</th>\n",
       "      <th>hiv4_positive_y</th>\n",
       "      <th>hiv4_negative_y</th>\n",
       "      <th>hiv4_polarity_y</th>\n",
       "      <th>hiv4_subjectivity_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.674050</td>\n",
       "      <td>-0.678073</td>\n",
       "      <td>-0.684392</td>\n",
       "      <td>-0.680826</td>\n",
       "      <td>-0.728849</td>\n",
       "      <td>0.109470</td>\n",
       "      <td>-0.669491</td>\n",
       "      <td>-0.676294</td>\n",
       "      <td>0.289320</td>\n",
       "      <td>0.599158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400564</td>\n",
       "      <td>-0.482217</td>\n",
       "      <td>-0.27749</td>\n",
       "      <td>-0.408061</td>\n",
       "      <td>-0.429498</td>\n",
       "      <td>-0.453309</td>\n",
       "      <td>-0.472809</td>\n",
       "      <td>-0.467669</td>\n",
       "      <td>-0.444618</td>\n",
       "      <td>-0.4625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.681984</td>\n",
       "      <td>-0.675172</td>\n",
       "      <td>-0.680596</td>\n",
       "      <td>-0.674561</td>\n",
       "      <td>-0.724596</td>\n",
       "      <td>-0.319954</td>\n",
       "      <td>-0.678062</td>\n",
       "      <td>-0.669177</td>\n",
       "      <td>-0.478101</td>\n",
       "      <td>0.302789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400564</td>\n",
       "      <td>-0.482217</td>\n",
       "      <td>-0.27749</td>\n",
       "      <td>-0.408061</td>\n",
       "      <td>-0.429498</td>\n",
       "      <td>-0.453309</td>\n",
       "      <td>-0.472809</td>\n",
       "      <td>-0.467669</td>\n",
       "      <td>-0.444618</td>\n",
       "      <td>-0.4625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close  Adj Close    Volume      sma2  \\\n",
       "0 -0.674050 -0.678073 -0.684392 -0.680826  -0.728849  0.109470 -0.669491   \n",
       "1 -0.681984 -0.675172 -0.680596 -0.674561  -0.724596 -0.319954 -0.678062   \n",
       "\n",
       "     sma2_1  sma2_increment  sma2_1_increment  ...  disgust_y  anticipation_y  \\\n",
       "0 -0.676294        0.289320          0.599158  ...  -0.400564       -0.482217   \n",
       "1 -0.669177       -0.478101          0.302789  ...  -0.400564       -0.482217   \n",
       "\n",
       "    fear_y   trust_y  tb_polarity_y  tb_subjectivity_y  hiv4_positive_y  \\\n",
       "0 -0.27749 -0.408061      -0.429498          -0.453309        -0.472809   \n",
       "1 -0.27749 -0.408061      -0.429498          -0.453309        -0.472809   \n",
       "\n",
       "   hiv4_negative_y  hiv4_polarity_y  hiv4_subjectivity_y  \n",
       "0        -0.467669        -0.444618              -0.4625  \n",
       "1        -0.467669        -0.444618              -0.4625  \n",
       "\n",
       "[2 rows x 77 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:24:46.019032Z",
     "start_time": "2019-04-27T17:24:42.292989Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\praveen ji\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.750\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.68      0.71       139\n",
      "         1.0       0.75      0.81      0.78       169\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       308\n",
      "   macro avg       0.75      0.74      0.75       308\n",
      "weighted avg       0.75      0.75      0.75       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = cCMatrixAccXGB(train , train_y, test,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:25:12.986277Z",
     "start_time": "2019-04-27T17:24:46.021026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "confusion_matrix [[105  34]\n",
      " [ 37 132]]\n",
      "number of datapoints in Up Class 169\n",
      "number of datapoints in Down Class 139\n",
      "accuracy_score 0.7694805194805194\n",
      "classification_score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.74      0.75       142\n",
      "         1.0       0.78      0.80      0.79       166\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       308\n",
      "   macro avg       0.77      0.77      0.77       308\n",
      "weighted avg       0.77      0.77      0.77       308\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "features = list(train.columns)\n",
    "k=cCMatrixAccRF(train , train_y, test,test_y, features,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:25:12.992287Z",
     "start_time": "2019-04-27T17:25:12.988270Z"
    }
   },
   "outputs": [],
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:25:13.003257Z",
     "start_time": "2019-04-27T17:25:12.994254Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_fiDf = train[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'sma2', 'sma2_1',\n",
    "#        'sma2_increment', 'sma2_1_increment', 'vol_increment',\n",
    "#        'vol_rel_increment',  'open_incr', 'ma7', 'ma21',\n",
    "#        '26ema', '12ema', 'MACD', '30 Day MA', '30 Day STD', 'upper_band',\n",
    "#        'lower_band', 'ema', 'momentum', 'log_momentum', 'fft', 'absolute',\n",
    "#        'angle']]\n",
    "# test_fiDf = test[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'sma2', 'sma2_1',\n",
    "#        'sma2_increment', 'sma2_1_increment', 'vol_increment',\n",
    "#        'vol_rel_increment',  'open_incr', 'ma7', 'ma21',\n",
    "#        '26ema', '12ema', 'MACD', '30 Day MA', '30 Day STD', 'upper_band',\n",
    "#        'lower_band', 'ema', 'momentum', 'log_momentum', 'fft', 'absolute',\n",
    "#        'angle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T17:25:13.009218Z",
     "start_time": "2019-04-27T17:25:13.005224Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_nwDf= train[[ 'lm_positive_x', 'lm_negative_x', 'lm_polarity_x',\n",
    "#        'lm_subjectivity_x', 'actvie_x', 'passive_x', 'weak_x', 'strong_x',\n",
    "#        'anger_x', 'joy_x', 'suprise_x', 'sadness_x', 'disgust_x',\n",
    "#        'anticipation_x', 'fear_x', 'trust_x', 'tb_polarity_x',\n",
    "#        'tb_subjectivity_x', 'hiv4_positive_x', 'hiv4_negative_x',\n",
    "#        'hiv4_polarity_x', 'hiv4_subjectivity_x', 'lm_positive_y']]\n",
    "# test_nwDf= test[[ 'lm_positive_x', 'lm_negative_x', 'lm_polarity_x',\n",
    "#        'lm_subjectivity_x', 'actvie_x', 'passive_x', 'weak_x', 'strong_x',\n",
    "#        'anger_x', 'joy_x', 'suprise_x', 'sadness_x', 'disgust_x',\n",
    "#        'anticipation_x', 'fear_x', 'trust_x', 'tb_polarity_x',\n",
    "#        'tb_subjectivity_x', 'hiv4_positive_x', 'hiv4_negative_x',\n",
    "#        'hiv4_polarity_x', 'hiv4_subjectivity_x', 'lm_positive_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:47:37.344491Z",
     "start_time": "2019-04-27T16:20:09.762Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_twDf= train[[ 'lm_negative_y', 'lm_polarity_y',\n",
    "#        'lm_subjectivity_y', 'actvie_y', 'passive_y', 'weak_y', 'strong_y',\n",
    "#        'anger_y', 'joy_y', 'suprise_y', 'sadness_y', 'disgust_y',\n",
    "#        'anticipation_y', 'fear_y', 'trust_y', 'tb_polarity_y',\n",
    "#        'tb_subjectivity_y', 'hiv4_positive_y', 'hiv4_negative_y', \n",
    "#        'retweet_count', 'hiv4_polarity_y', 'hiv4_subjectivity_y']]\n",
    "# test_twDf= test[[ 'lm_negative_y', 'lm_polarity_y',\n",
    "#        'lm_subjectivity_y', 'actvie_y', 'passive_y', 'weak_y', 'strong_y',\n",
    "#        'anger_y', 'joy_y', 'suprise_y', 'sadness_y', 'disgust_y',\n",
    "#        'anticipation_y', 'fear_y', 'trust_y', 'tb_polarity_y',\n",
    "#        'tb_subjectivity_y', 'hiv4_positive_y', 'hiv4_negative_y', \n",
    "#        'retweet_count', 'hiv4_polarity_y', 'hiv4_subjectivity_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:47:37.345487Z",
     "start_time": "2019-04-27T16:20:09.766Z"
    }
   },
   "outputs": [],
   "source": [
    "# col_names =  ['news', 'tweeter', 'financialIndicator','target']\n",
    "# YHat_test  = pd.DataFrame(columns = col_names)\n",
    "# YHat_train = pd.DataFrame(columns = col_names)\n",
    "# YHat_test['target'] = test_y\n",
    "# YHat_train['target'] = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:47:37.346487Z",
     "start_time": "2019-04-27T16:20:09.770Z"
    }
   },
   "outputs": [],
   "source": [
    "# col_names =  ['news', 'tweeter', 'financialIndicator','target']\n",
    "# YHat_rf_test  = pd.DataFrame(columns = col_names)\n",
    "# YHat_rf_train = pd.DataFrame(columns = col_names)\n",
    "# YHat_rf_test['target'] = test_y\n",
    "# YHat_rf_train['target'] = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:47:37.347483Z",
     "start_time": "2019-04-27T16:20:09.773Z"
    }
   },
   "outputs": [],
   "source": [
    "# YHat_test['news'] = cCMatrixAccXGB(train_nwDf , train_y, test_nwDf,test_y)\n",
    "# YHat_train['news'] = cCMatrixAccXGB(train_nwDf , train_y, train_nwDf,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:47:37.348480Z",
     "start_time": "2019-04-27T16:20:09.777Z"
    }
   },
   "outputs": [],
   "source": [
    "# YHat_rf_train['news'], YHat_rf_test['news'] = cCMatrixAccRF(train_nwDf , train_y, test_nwDf,test_y, list(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:47:37.349476Z",
     "start_time": "2019-04-27T16:20:09.780Z"
    }
   },
   "outputs": [],
   "source": [
    "# YHat_test['tweeter'] = cCMatrixAccXGB(train_twDf , train_y, test_twDf,test_y)\n",
    "# YHat_train['tweeter'] = cCMatrixAccXGB(train_twDf , train_y, train_twDf,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:47:37.351473Z",
     "start_time": "2019-04-27T16:20:09.783Z"
    }
   },
   "outputs": [],
   "source": [
    "# YHat_test['tweeter'] = cCMatrixAccXGB(train_twDf , train_y, test_twDf,test_y)\n",
    "# YHat_train['tweeter'] = cCMatrixAccXGB(train_twDf , train_y, train_twDf,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:47:37.352478Z",
     "start_time": "2019-04-27T16:20:09.789Z"
    }
   },
   "outputs": [],
   "source": [
    "# YHat_test['financialIndicator'] = cCMatrixAccXGB(train_fiDf , train_y, test_fiDf,test_y)\n",
    "# YHat_train['financialIndicator'] = cCMatrixAccXGB(train_fiDf , train_y, train_fiDf,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:47:37.353473Z",
     "start_time": "2019-04-27T16:20:09.792Z"
    }
   },
   "outputs": [],
   "source": [
    "# YHat_test['financialIndicator'] = cCMatrixAccXGB(train_fiDf , train_y, test_fiDf,test_y)\n",
    "# YHat_train['financialIndicator'] = cCMatrixAccXGB(train_fiDf , train_y, train_fiDf,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:47:37.354466Z",
     "start_time": "2019-04-27T16:20:09.796Z"
    }
   },
   "outputs": [],
   "source": [
    "# YHat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:47:37.356458Z",
     "start_time": "2019-04-27T16:20:09.800Z"
    }
   },
   "outputs": [],
   "source": [
    "# YHat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T16:47:37.357455Z",
     "start_time": "2019-04-27T16:20:09.805Z"
    }
   },
   "outputs": [],
   "source": [
    "# temp = cCMatrixAccXGB(YHat_train.drop('target',axis =1) , YHat_train['target'],YHat_test.drop('target',axis =1) , YHat_test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "330.4px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
